{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training experimental models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 21:24:12.684208: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-08 21:24:12.746947: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-08 21:24:12.748229: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-08 21:24:13.734762: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset.dataset import load_fashion_mnist_dataset\n",
    "\n",
    "X_train, X_test = load_fashion_mnist_dataset()\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_dim = X_train[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickle_results(dim: int, learning_rate: float, batch_size: int, optimizer: Optimizer, autoencoder: Autoencoder):\n",
    "    with open(f\"saved_models/networks/autoencoder_{dim}_{learning_rate}_{batch_size}\", 'wb') as pickle_file:\n",
    "        pickle.dump(autoencoder, pickle_file)\n",
    "\n",
    "    with open(f\"saved_models/optimizers/optimizer_{dim}_{learning_rate}_{batch_size}\", 'wb') as pickle_file:\n",
    "        pickle.dump(optimizer, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dims = [12, 36, 108]\n",
    "learning_rates = [1, 0.9, 0.09]\n",
    "batch_sizes = [16, 128, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  -- accuracy 0.002 - loss 0.136\n",
      "Epoch 1  -- accuracy 0.002 - loss 0.093\n",
      "Epoch 2  -- accuracy 0.002 - loss 0.088\n",
      "Epoch 3  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 4  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 5  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 6  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 7  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 8  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 9  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 10  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 11  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 12  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 13  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 14  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 15  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 16  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 17  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 18  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 19  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 20  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 21  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 22  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 23  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 24  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 25  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 26  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 27  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 28  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 29  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 30  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 31  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 32  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 33  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 34  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 35  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 36  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 37  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 38  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 39  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 40  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 41  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 42  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 43  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 44  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 45  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 46  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 47  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 48  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 49  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 50  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 51  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 52  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 53  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 54  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 55  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 56  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 57  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 58  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 59  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 60  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 61  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 62  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 63  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 64  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 65  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 66  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 67  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 68  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 69  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 70  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 71  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 72  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 73  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 74  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 75  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 76  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 77  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 78  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 79  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 80  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 81  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 82  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 83  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 84  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 85  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 86  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 87  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 88  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 89  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 90  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 91  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 92  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 93  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 94  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 95  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 96  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 97  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 98  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 99  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 100  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 101  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 102  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 103  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 104  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 105  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 106  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 107  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 108  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 109  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 110  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 111  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 112  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 113  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 114  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 115  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 116  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 117  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 118  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 119  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 120  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 121  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 122  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 123  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 124  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 125  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 126  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 127  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 128  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 129  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 130  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 131  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 132  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 133  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 134  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 135  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 136  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 137  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 138  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 139  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 140  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 141  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 142  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 143  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 144  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 145  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 146  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 147  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 148  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 149  -- accuracy 0.002 - loss 0.087\n",
      "Epoch 0  -- accuracy 0.002 - loss 0.135\n",
      "Epoch 1  -- accuracy 0.002 - loss 0.081\n",
      "Epoch 2  -- accuracy 0.002 - loss 0.069\n",
      "Epoch 3  -- accuracy 0.002 - loss 0.064\n",
      "Epoch 4  -- accuracy 0.002 - loss 0.060\n",
      "Epoch 5  -- accuracy 0.002 - loss 0.056\n",
      "Epoch 6  -- accuracy 0.003 - loss 0.051\n",
      "Epoch 7  -- accuracy 0.004 - loss 0.048\n",
      "Epoch 8  -- accuracy 0.005 - loss 0.046\n",
      "Epoch 9  -- accuracy 0.005 - loss 0.045\n",
      "Epoch 10  -- accuracy 0.005 - loss 0.044\n",
      "Epoch 11  -- accuracy 0.006 - loss 0.043\n",
      "Epoch 12  -- accuracy 0.007 - loss 0.042\n",
      "Epoch 13  -- accuracy 0.007 - loss 0.041\n",
      "Epoch 14  -- accuracy 0.007 - loss 0.040\n",
      "Epoch 15  -- accuracy 0.007 - loss 0.039\n",
      "Epoch 16  -- accuracy 0.007 - loss 0.039\n",
      "Epoch 17  -- accuracy 0.007 - loss 0.038\n",
      "Epoch 18  -- accuracy 0.007 - loss 0.037\n",
      "Epoch 19  -- accuracy 0.008 - loss 0.036\n",
      "Epoch 20  -- accuracy 0.008 - loss 0.036\n",
      "Epoch 21  -- accuracy 0.008 - loss 0.035\n",
      "Epoch 22  -- accuracy 0.008 - loss 0.035\n",
      "Epoch 23  -- accuracy 0.009 - loss 0.034\n",
      "Epoch 24  -- accuracy 0.009 - loss 0.034\n",
      "Epoch 25  -- accuracy 0.009 - loss 0.033\n",
      "Epoch 26  -- accuracy 0.009 - loss 0.033\n",
      "Epoch 27  -- accuracy 0.009 - loss 0.032\n",
      "Epoch 28  -- accuracy 0.009 - loss 0.032\n",
      "Epoch 29  -- accuracy 0.009 - loss 0.031\n",
      "Epoch 30  -- accuracy 0.009 - loss 0.031\n",
      "Epoch 31  -- accuracy 0.009 - loss 0.031\n",
      "Epoch 32  -- accuracy 0.009 - loss 0.031\n",
      "Epoch 33  -- accuracy 0.009 - loss 0.030\n",
      "Epoch 34  -- accuracy 0.009 - loss 0.030\n",
      "Epoch 35  -- accuracy 0.009 - loss 0.030\n",
      "Epoch 36  -- accuracy 0.009 - loss 0.030\n",
      "Epoch 37  -- accuracy 0.009 - loss 0.030\n",
      "Epoch 38  -- accuracy 0.010 - loss 0.029\n",
      "Epoch 39  -- accuracy 0.010 - loss 0.029\n",
      "Epoch 40  -- accuracy 0.010 - loss 0.029\n",
      "Epoch 41  -- accuracy 0.010 - loss 0.029\n",
      "Epoch 42  -- accuracy 0.010 - loss 0.029\n",
      "Epoch 43  -- accuracy 0.010 - loss 0.028\n",
      "Epoch 44  -- accuracy 0.010 - loss 0.028\n",
      "Epoch 45  -- accuracy 0.011 - loss 0.028\n",
      "Epoch 46  -- accuracy 0.010 - loss 0.028\n",
      "Epoch 47  -- accuracy 0.011 - loss 0.028\n",
      "Epoch 48  -- accuracy 0.011 - loss 0.028\n",
      "Epoch 49  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 50  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 51  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 52  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 53  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 54  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 55  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 56  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 57  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 58  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 59  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 60  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 61  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 62  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 63  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 64  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 65  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 66  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 67  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 68  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 69  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 70  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 71  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 72  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 73  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 74  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 75  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 76  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 77  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 78  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 79  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 80  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 81  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 82  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 83  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 84  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 85  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 86  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 87  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 88  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 89  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 90  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 91  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 92  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 93  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 94  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 95  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 96  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 97  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 98  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 99  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 100  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 101  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 102  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 103  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 104  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 105  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 106  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 107  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 108  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 109  -- accuracy 0.010 - loss 0.024\n",
      "Epoch 110  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 111  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 112  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 113  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 114  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 115  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 116  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 117  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 118  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 119  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 120  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 121  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 122  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 123  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 124  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 125  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 126  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 127  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 128  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 129  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 130  -- accuracy 0.010 - loss 0.023\n",
      "Epoch 131  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 132  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 133  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 134  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 135  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 136  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 137  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 138  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 139  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 140  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 141  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 142  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 143  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 144  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 145  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 146  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 147  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 148  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 149  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 0  -- accuracy 0.002 - loss 0.075\n",
      "Epoch 1  -- accuracy 0.003 - loss 0.046\n",
      "Epoch 2  -- accuracy 0.005 - loss 0.040\n",
      "Epoch 3  -- accuracy 0.007 - loss 0.036\n",
      "Epoch 4  -- accuracy 0.009 - loss 0.033\n",
      "Epoch 5  -- accuracy 0.009 - loss 0.031\n",
      "Epoch 6  -- accuracy 0.010 - loss 0.029\n",
      "Epoch 7  -- accuracy 0.011 - loss 0.028\n",
      "Epoch 8  -- accuracy 0.012 - loss 0.027\n",
      "Epoch 9  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 10  -- accuracy 0.013 - loss 0.025\n",
      "Epoch 11  -- accuracy 0.013 - loss 0.025\n",
      "Epoch 12  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 13  -- accuracy 0.014 - loss 0.024\n",
      "Epoch 14  -- accuracy 0.015 - loss 0.023\n",
      "Epoch 15  -- accuracy 0.015 - loss 0.023\n",
      "Epoch 16  -- accuracy 0.015 - loss 0.023\n",
      "Epoch 17  -- accuracy 0.015 - loss 0.022\n",
      "Epoch 18  -- accuracy 0.015 - loss 0.022\n",
      "Epoch 19  -- accuracy 0.015 - loss 0.022\n",
      "Epoch 20  -- accuracy 0.015 - loss 0.021\n",
      "Epoch 21  -- accuracy 0.015 - loss 0.021\n",
      "Epoch 22  -- accuracy 0.015 - loss 0.021\n",
      "Epoch 23  -- accuracy 0.016 - loss 0.021\n",
      "Epoch 24  -- accuracy 0.016 - loss 0.021\n",
      "Epoch 25  -- accuracy 0.016 - loss 0.020\n",
      "Epoch 26  -- accuracy 0.016 - loss 0.020\n",
      "Epoch 27  -- accuracy 0.016 - loss 0.020\n",
      "Epoch 28  -- accuracy 0.017 - loss 0.020\n",
      "Epoch 29  -- accuracy 0.017 - loss 0.020\n",
      "Epoch 30  -- accuracy 0.017 - loss 0.019\n",
      "Epoch 31  -- accuracy 0.017 - loss 0.019\n",
      "Epoch 32  -- accuracy 0.017 - loss 0.019\n",
      "Epoch 33  -- accuracy 0.018 - loss 0.019\n",
      "Epoch 34  -- accuracy 0.017 - loss 0.019\n",
      "Epoch 35  -- accuracy 0.018 - loss 0.019\n",
      "Epoch 36  -- accuracy 0.018 - loss 0.019\n",
      "Epoch 37  -- accuracy 0.018 - loss 0.018\n",
      "Epoch 38  -- accuracy 0.018 - loss 0.018\n",
      "Epoch 39  -- accuracy 0.018 - loss 0.018\n",
      "Epoch 40  -- accuracy 0.018 - loss 0.018\n",
      "Epoch 41  -- accuracy 0.019 - loss 0.018\n",
      "Epoch 42  -- accuracy 0.019 - loss 0.018\n",
      "Epoch 43  -- accuracy 0.019 - loss 0.018\n",
      "Epoch 44  -- accuracy 0.019 - loss 0.018\n",
      "Epoch 45  -- accuracy 0.019 - loss 0.017\n",
      "Epoch 46  -- accuracy 0.019 - loss 0.017\n",
      "Epoch 47  -- accuracy 0.019 - loss 0.017\n",
      "Epoch 48  -- accuracy 0.020 - loss 0.017\n",
      "Epoch 49  -- accuracy 0.020 - loss 0.017\n",
      "Epoch 50  -- accuracy 0.020 - loss 0.017\n",
      "Epoch 51  -- accuracy 0.020 - loss 0.017\n",
      "Epoch 52  -- accuracy 0.020 - loss 0.017\n",
      "Epoch 53  -- accuracy 0.020 - loss 0.017\n",
      "Epoch 54  -- accuracy 0.020 - loss 0.017\n",
      "Epoch 55  -- accuracy 0.021 - loss 0.016\n",
      "Epoch 56  -- accuracy 0.021 - loss 0.016\n",
      "Epoch 57  -- accuracy 0.021 - loss 0.016\n",
      "Epoch 58  -- accuracy 0.021 - loss 0.016\n",
      "Epoch 59  -- accuracy 0.021 - loss 0.016\n",
      "Epoch 60  -- accuracy 0.021 - loss 0.016\n",
      "Epoch 61  -- accuracy 0.022 - loss 0.016\n",
      "Epoch 62  -- accuracy 0.021 - loss 0.016\n",
      "Epoch 63  -- accuracy 0.022 - loss 0.016\n",
      "Epoch 64  -- accuracy 0.022 - loss 0.016\n",
      "Epoch 65  -- accuracy 0.022 - loss 0.016\n",
      "Epoch 66  -- accuracy 0.022 - loss 0.016\n",
      "Epoch 67  -- accuracy 0.022 - loss 0.016\n",
      "Epoch 68  -- accuracy 0.023 - loss 0.015\n",
      "Epoch 69  -- accuracy 0.023 - loss 0.015\n",
      "Epoch 70  -- accuracy 0.023 - loss 0.015\n",
      "Epoch 71  -- accuracy 0.023 - loss 0.015\n",
      "Epoch 72  -- accuracy 0.023 - loss 0.015\n",
      "Epoch 73  -- accuracy 0.023 - loss 0.015\n",
      "Epoch 74  -- accuracy 0.023 - loss 0.015\n",
      "Epoch 75  -- accuracy 0.023 - loss 0.015\n",
      "Epoch 76  -- accuracy 0.023 - loss 0.015\n",
      "Epoch 77  -- accuracy 0.023 - loss 0.015\n",
      "Epoch 78  -- accuracy 0.023 - loss 0.015\n",
      "Epoch 79  -- accuracy 0.024 - loss 0.015\n",
      "Epoch 80  -- accuracy 0.024 - loss 0.015\n",
      "Epoch 81  -- accuracy 0.024 - loss 0.015\n",
      "Epoch 82  -- accuracy 0.024 - loss 0.015\n",
      "Epoch 83  -- accuracy 0.024 - loss 0.015\n",
      "Epoch 84  -- accuracy 0.024 - loss 0.015\n",
      "Epoch 85  -- accuracy 0.024 - loss 0.015\n",
      "Epoch 86  -- accuracy 0.024 - loss 0.015\n",
      "Epoch 87  -- accuracy 0.025 - loss 0.014\n",
      "Epoch 88  -- accuracy 0.025 - loss 0.014\n",
      "Epoch 89  -- accuracy 0.025 - loss 0.014\n",
      "Epoch 90  -- accuracy 0.025 - loss 0.014\n",
      "Epoch 91  -- accuracy 0.025 - loss 0.014\n",
      "Epoch 92  -- accuracy 0.025 - loss 0.014\n",
      "Epoch 93  -- accuracy 0.025 - loss 0.014\n",
      "Epoch 94  -- accuracy 0.025 - loss 0.014\n",
      "Epoch 95  -- accuracy 0.025 - loss 0.014\n",
      "Epoch 96  -- accuracy 0.026 - loss 0.014\n",
      "Epoch 97  -- accuracy 0.026 - loss 0.014\n",
      "Epoch 98  -- accuracy 0.026 - loss 0.014\n",
      "Epoch 99  -- accuracy 0.026 - loss 0.014\n",
      "Epoch 100  -- accuracy 0.026 - loss 0.014\n",
      "Epoch 101  -- accuracy 0.026 - loss 0.014\n",
      "Epoch 102  -- accuracy 0.026 - loss 0.014\n",
      "Epoch 103  -- accuracy 0.026 - loss 0.014\n",
      "Epoch 104  -- accuracy 0.027 - loss 0.014\n",
      "Epoch 105  -- accuracy 0.026 - loss 0.014\n",
      "Epoch 106  -- accuracy 0.027 - loss 0.014\n",
      "Epoch 107  -- accuracy 0.027 - loss 0.014\n",
      "Epoch 108  -- accuracy 0.027 - loss 0.014\n",
      "Epoch 109  -- accuracy 0.027 - loss 0.014\n",
      "Epoch 110  -- accuracy 0.027 - loss 0.014\n",
      "Epoch 111  -- accuracy 0.027 - loss 0.014\n",
      "Epoch 112  -- accuracy 0.027 - loss 0.014\n",
      "Epoch 113  -- accuracy 0.027 - loss 0.014\n",
      "Epoch 114  -- accuracy 0.027 - loss 0.014\n",
      "Epoch 115  -- accuracy 0.027 - loss 0.014\n",
      "Epoch 116  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 117  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 118  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 119  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 120  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 121  -- accuracy 0.027 - loss 0.013\n",
      "Epoch 122  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 123  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 124  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 125  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 126  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 127  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 128  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 129  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 130  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 131  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 132  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 133  -- accuracy 0.028 - loss 0.013\n",
      "Epoch 134  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 135  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 136  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 137  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 138  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 139  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 140  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 141  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 142  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 143  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 144  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 145  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 146  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 147  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 148  -- accuracy 0.029 - loss 0.013\n",
      "Epoch 149  -- accuracy 0.029 - loss 0.013\n"
     ]
    }
   ],
   "source": [
    "# Code dim\n",
    "\n",
    "learning_rate=learning_rates[1]\n",
    "batch_size=batch_sizes[1]\n",
    "\n",
    "for code_dim in code_dims:\n",
    "    autoencoder = Autoencoder(input_dim=flatten_dim, code_dim=code_dim, encoder_hidden_count=0, reduce_by=1.5)\n",
    "    optimizer = Optimizer(\n",
    "        autoencoder,\n",
    "        loss=MeanSquaredError(),\n",
    "        accuracy=Accuracy(),\n",
    "        learning_rate=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        epochs=150,\n",
    "    )\n",
    "    \n",
    "    optimizer.fit(X_train, X_train)\n",
    "\n",
    "    pickle_results(code_dim, learning_rate, batch_size, optimizer, autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  -- accuracy 0.001 - loss 0.133\n",
      "Epoch 1  -- accuracy 0.001 - loss 0.091\n",
      "Epoch 2  -- accuracy 0.001 - loss 0.087\n",
      "Epoch 3  -- accuracy 0.001 - loss 0.085\n",
      "Epoch 4  -- accuracy 0.001 - loss 0.082\n",
      "Epoch 5  -- accuracy 0.002 - loss 0.076\n",
      "Epoch 6  -- accuracy 0.003 - loss 0.069\n",
      "Epoch 7  -- accuracy 0.004 - loss 0.063\n",
      "Epoch 8  -- accuracy 0.004 - loss 0.058\n",
      "Epoch 9  -- accuracy 0.004 - loss 0.053\n",
      "Epoch 10  -- accuracy 0.004 - loss 0.050\n",
      "Epoch 11  -- accuracy 0.004 - loss 0.047\n",
      "Epoch 12  -- accuracy 0.004 - loss 0.045\n",
      "Epoch 13  -- accuracy 0.004 - loss 0.044\n",
      "Epoch 14  -- accuracy 0.005 - loss 0.043\n",
      "Epoch 15  -- accuracy 0.006 - loss 0.041\n",
      "Epoch 16  -- accuracy 0.006 - loss 0.040\n",
      "Epoch 17  -- accuracy 0.007 - loss 0.040\n",
      "Epoch 18  -- accuracy 0.007 - loss 0.039\n",
      "Epoch 19  -- accuracy 0.007 - loss 0.038\n",
      "Epoch 20  -- accuracy 0.007 - loss 0.038\n",
      "Epoch 21  -- accuracy 0.007 - loss 0.037\n",
      "Epoch 22  -- accuracy 0.008 - loss 0.037\n",
      "Epoch 23  -- accuracy 0.008 - loss 0.037\n",
      "Epoch 24  -- accuracy 0.008 - loss 0.037\n",
      "Epoch 25  -- accuracy 0.008 - loss 0.036\n",
      "Epoch 26  -- accuracy 0.008 - loss 0.036\n",
      "Epoch 27  -- accuracy 0.008 - loss 0.036\n",
      "Epoch 28  -- accuracy 0.009 - loss 0.035\n",
      "Epoch 29  -- accuracy 0.008 - loss 0.035\n",
      "Epoch 30  -- accuracy 0.008 - loss 0.034\n",
      "Epoch 31  -- accuracy 0.008 - loss 0.034\n",
      "Epoch 32  -- accuracy 0.008 - loss 0.034\n",
      "Epoch 33  -- accuracy 0.008 - loss 0.033\n",
      "Epoch 34  -- accuracy 0.009 - loss 0.033\n",
      "Epoch 35  -- accuracy 0.009 - loss 0.033\n",
      "Epoch 36  -- accuracy 0.009 - loss 0.033\n",
      "Epoch 37  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 38  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 39  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 40  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 41  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 42  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 43  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 44  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 45  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 46  -- accuracy 0.012 - loss 0.030\n",
      "Epoch 47  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 48  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 49  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 50  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 51  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 52  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 53  -- accuracy 0.011 - loss 0.029\n",
      "Epoch 54  -- accuracy 0.011 - loss 0.029\n",
      "Epoch 55  -- accuracy 0.011 - loss 0.029\n",
      "Epoch 56  -- accuracy 0.011 - loss 0.029\n",
      "Epoch 57  -- accuracy 0.011 - loss 0.029\n",
      "Epoch 58  -- accuracy 0.011 - loss 0.029\n",
      "Epoch 59  -- accuracy 0.011 - loss 0.029\n",
      "Epoch 60  -- accuracy 0.012 - loss 0.028\n",
      "Epoch 61  -- accuracy 0.011 - loss 0.028\n",
      "Epoch 62  -- accuracy 0.011 - loss 0.028\n",
      "Epoch 63  -- accuracy 0.011 - loss 0.028\n",
      "Epoch 64  -- accuracy 0.011 - loss 0.028\n",
      "Epoch 65  -- accuracy 0.011 - loss 0.028\n",
      "Epoch 66  -- accuracy 0.011 - loss 0.028\n",
      "Epoch 67  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 68  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 69  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 70  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 71  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 72  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 73  -- accuracy 0.012 - loss 0.027\n",
      "Epoch 74  -- accuracy 0.012 - loss 0.027\n",
      "Epoch 75  -- accuracy 0.012 - loss 0.027\n",
      "Epoch 76  -- accuracy 0.012 - loss 0.027\n",
      "Epoch 77  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 78  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 79  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 80  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 81  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 82  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 83  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 84  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 85  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 86  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 87  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 88  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 89  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 90  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 91  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 92  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 93  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 94  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 95  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 96  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 97  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 98  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 99  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 100  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 101  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 102  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 103  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 104  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 105  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 106  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 107  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 108  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 109  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 110  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 111  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 112  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 113  -- accuracy 0.012 - loss 0.025\n",
      "Epoch 114  -- accuracy 0.012 - loss 0.025\n",
      "Epoch 115  -- accuracy 0.012 - loss 0.024\n",
      "Epoch 116  -- accuracy 0.012 - loss 0.024\n",
      "Epoch 117  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 118  -- accuracy 0.012 - loss 0.024\n",
      "Epoch 119  -- accuracy 0.012 - loss 0.024\n",
      "Epoch 120  -- accuracy 0.012 - loss 0.024\n",
      "Epoch 121  -- accuracy 0.012 - loss 0.024\n",
      "Epoch 122  -- accuracy 0.012 - loss 0.024\n",
      "Epoch 123  -- accuracy 0.012 - loss 0.024\n",
      "Epoch 124  -- accuracy 0.012 - loss 0.024\n",
      "Epoch 125  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 126  -- accuracy 0.012 - loss 0.024\n",
      "Epoch 127  -- accuracy 0.012 - loss 0.024\n",
      "Epoch 128  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 129  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 130  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 131  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 132  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 133  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 134  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 135  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 136  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 137  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 138  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 139  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 140  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 141  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 142  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 143  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 144  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 145  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 146  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 147  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 148  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 149  -- accuracy 0.013 - loss 0.024\n",
      "Epoch 0  -- accuracy 0.001 - loss 0.193\n",
      "Epoch 1  -- accuracy 0.001 - loss 0.168\n",
      "Epoch 2  -- accuracy 0.001 - loss 0.145\n",
      "Epoch 3  -- accuracy 0.001 - loss 0.123\n",
      "Epoch 4  -- accuracy 0.001 - loss 0.104\n",
      "Epoch 5  -- accuracy 0.001 - loss 0.089\n",
      "Epoch 6  -- accuracy 0.001 - loss 0.079\n",
      "Epoch 7  -- accuracy 0.001 - loss 0.073\n",
      "Epoch 8  -- accuracy 0.001 - loss 0.070\n",
      "Epoch 9  -- accuracy 0.001 - loss 0.068\n",
      "Epoch 10  -- accuracy 0.001 - loss 0.067\n",
      "Epoch 11  -- accuracy 0.001 - loss 0.066\n",
      "Epoch 12  -- accuracy 0.001 - loss 0.066\n",
      "Epoch 13  -- accuracy 0.001 - loss 0.065\n",
      "Epoch 14  -- accuracy 0.001 - loss 0.065\n",
      "Epoch 15  -- accuracy 0.001 - loss 0.065\n",
      "Epoch 16  -- accuracy 0.001 - loss 0.065\n",
      "Epoch 17  -- accuracy 0.002 - loss 0.064\n",
      "Epoch 18  -- accuracy 0.002 - loss 0.064\n",
      "Epoch 19  -- accuracy 0.002 - loss 0.064\n",
      "Epoch 20  -- accuracy 0.002 - loss 0.064\n",
      "Epoch 21  -- accuracy 0.002 - loss 0.063\n",
      "Epoch 22  -- accuracy 0.002 - loss 0.063\n",
      "Epoch 23  -- accuracy 0.002 - loss 0.063\n",
      "Epoch 24  -- accuracy 0.002 - loss 0.063\n",
      "Epoch 25  -- accuracy 0.002 - loss 0.062\n",
      "Epoch 26  -- accuracy 0.002 - loss 0.062\n",
      "Epoch 27  -- accuracy 0.002 - loss 0.062\n",
      "Epoch 28  -- accuracy 0.002 - loss 0.062\n",
      "Epoch 29  -- accuracy 0.002 - loss 0.061\n",
      "Epoch 30  -- accuracy 0.002 - loss 0.061\n",
      "Epoch 31  -- accuracy 0.002 - loss 0.061\n",
      "Epoch 32  -- accuracy 0.002 - loss 0.060\n",
      "Epoch 33  -- accuracy 0.002 - loss 0.060\n",
      "Epoch 34  -- accuracy 0.002 - loss 0.060\n",
      "Epoch 35  -- accuracy 0.002 - loss 0.059\n",
      "Epoch 36  -- accuracy 0.002 - loss 0.059\n",
      "Epoch 37  -- accuracy 0.002 - loss 0.058\n",
      "Epoch 38  -- accuracy 0.002 - loss 0.058\n",
      "Epoch 39  -- accuracy 0.002 - loss 0.057\n",
      "Epoch 40  -- accuracy 0.002 - loss 0.057\n",
      "Epoch 41  -- accuracy 0.002 - loss 0.057\n",
      "Epoch 42  -- accuracy 0.002 - loss 0.056\n",
      "Epoch 43  -- accuracy 0.002 - loss 0.056\n",
      "Epoch 44  -- accuracy 0.002 - loss 0.055\n",
      "Epoch 45  -- accuracy 0.002 - loss 0.055\n",
      "Epoch 46  -- accuracy 0.002 - loss 0.054\n",
      "Epoch 47  -- accuracy 0.002 - loss 0.054\n",
      "Epoch 48  -- accuracy 0.002 - loss 0.053\n",
      "Epoch 49  -- accuracy 0.002 - loss 0.053\n",
      "Epoch 50  -- accuracy 0.002 - loss 0.052\n",
      "Epoch 51  -- accuracy 0.002 - loss 0.052\n",
      "Epoch 52  -- accuracy 0.002 - loss 0.051\n",
      "Epoch 53  -- accuracy 0.002 - loss 0.051\n",
      "Epoch 54  -- accuracy 0.002 - loss 0.051\n",
      "Epoch 55  -- accuracy 0.002 - loss 0.050\n",
      "Epoch 56  -- accuracy 0.002 - loss 0.050\n",
      "Epoch 57  -- accuracy 0.002 - loss 0.049\n",
      "Epoch 58  -- accuracy 0.002 - loss 0.049\n",
      "Epoch 59  -- accuracy 0.002 - loss 0.049\n",
      "Epoch 60  -- accuracy 0.002 - loss 0.048\n",
      "Epoch 61  -- accuracy 0.002 - loss 0.048\n",
      "Epoch 62  -- accuracy 0.003 - loss 0.048\n",
      "Epoch 63  -- accuracy 0.003 - loss 0.048\n",
      "Epoch 64  -- accuracy 0.004 - loss 0.047\n",
      "Epoch 65  -- accuracy 0.004 - loss 0.047\n",
      "Epoch 66  -- accuracy 0.005 - loss 0.047\n",
      "Epoch 67  -- accuracy 0.006 - loss 0.047\n",
      "Epoch 68  -- accuracy 0.006 - loss 0.046\n",
      "Epoch 69  -- accuracy 0.007 - loss 0.046\n",
      "Epoch 70  -- accuracy 0.008 - loss 0.046\n",
      "Epoch 71  -- accuracy 0.008 - loss 0.046\n",
      "Epoch 72  -- accuracy 0.009 - loss 0.046\n",
      "Epoch 73  -- accuracy 0.009 - loss 0.046\n",
      "Epoch 74  -- accuracy 0.010 - loss 0.045\n",
      "Epoch 75  -- accuracy 0.010 - loss 0.045\n",
      "Epoch 76  -- accuracy 0.011 - loss 0.045\n",
      "Epoch 77  -- accuracy 0.011 - loss 0.045\n",
      "Epoch 78  -- accuracy 0.012 - loss 0.045\n",
      "Epoch 79  -- accuracy 0.012 - loss 0.045\n",
      "Epoch 80  -- accuracy 0.012 - loss 0.045\n",
      "Epoch 81  -- accuracy 0.013 - loss 0.044\n",
      "Epoch 82  -- accuracy 0.013 - loss 0.044\n",
      "Epoch 83  -- accuracy 0.013 - loss 0.044\n",
      "Epoch 84  -- accuracy 0.013 - loss 0.044\n",
      "Epoch 85  -- accuracy 0.013 - loss 0.044\n",
      "Epoch 86  -- accuracy 0.014 - loss 0.044\n",
      "Epoch 87  -- accuracy 0.014 - loss 0.044\n",
      "Epoch 88  -- accuracy 0.014 - loss 0.044\n",
      "Epoch 89  -- accuracy 0.014 - loss 0.044\n",
      "Epoch 90  -- accuracy 0.014 - loss 0.044\n",
      "Epoch 91  -- accuracy 0.014 - loss 0.043\n",
      "Epoch 92  -- accuracy 0.014 - loss 0.043\n",
      "Epoch 93  -- accuracy 0.014 - loss 0.043\n",
      "Epoch 94  -- accuracy 0.014 - loss 0.043\n",
      "Epoch 95  -- accuracy 0.014 - loss 0.043\n",
      "Epoch 96  -- accuracy 0.014 - loss 0.043\n",
      "Epoch 97  -- accuracy 0.014 - loss 0.043\n",
      "Epoch 98  -- accuracy 0.014 - loss 0.043\n",
      "Epoch 99  -- accuracy 0.014 - loss 0.043\n",
      "Epoch 100  -- accuracy 0.014 - loss 0.043\n",
      "Epoch 101  -- accuracy 0.014 - loss 0.043\n",
      "Epoch 102  -- accuracy 0.014 - loss 0.043\n",
      "Epoch 103  -- accuracy 0.014 - loss 0.042\n",
      "Epoch 104  -- accuracy 0.014 - loss 0.042\n",
      "Epoch 105  -- accuracy 0.015 - loss 0.042\n",
      "Epoch 106  -- accuracy 0.014 - loss 0.042\n",
      "Epoch 107  -- accuracy 0.014 - loss 0.042\n",
      "Epoch 108  -- accuracy 0.014 - loss 0.042\n",
      "Epoch 109  -- accuracy 0.014 - loss 0.042\n",
      "Epoch 110  -- accuracy 0.014 - loss 0.042\n",
      "Epoch 111  -- accuracy 0.014 - loss 0.042\n",
      "Epoch 112  -- accuracy 0.014 - loss 0.042\n",
      "Epoch 113  -- accuracy 0.015 - loss 0.042\n",
      "Epoch 114  -- accuracy 0.015 - loss 0.042\n",
      "Epoch 115  -- accuracy 0.015 - loss 0.041\n",
      "Epoch 116  -- accuracy 0.015 - loss 0.041\n",
      "Epoch 117  -- accuracy 0.015 - loss 0.041\n",
      "Epoch 118  -- accuracy 0.015 - loss 0.041\n",
      "Epoch 119  -- accuracy 0.015 - loss 0.041\n",
      "Epoch 120  -- accuracy 0.015 - loss 0.041\n",
      "Epoch 121  -- accuracy 0.015 - loss 0.041\n",
      "Epoch 122  -- accuracy 0.015 - loss 0.041\n",
      "Epoch 123  -- accuracy 0.015 - loss 0.041\n",
      "Epoch 124  -- accuracy 0.015 - loss 0.041\n",
      "Epoch 125  -- accuracy 0.015 - loss 0.041\n",
      "Epoch 126  -- accuracy 0.015 - loss 0.040\n",
      "Epoch 127  -- accuracy 0.015 - loss 0.040\n",
      "Epoch 128  -- accuracy 0.015 - loss 0.040\n",
      "Epoch 129  -- accuracy 0.015 - loss 0.040\n",
      "Epoch 130  -- accuracy 0.015 - loss 0.040\n",
      "Epoch 131  -- accuracy 0.015 - loss 0.040\n",
      "Epoch 132  -- accuracy 0.015 - loss 0.040\n",
      "Epoch 133  -- accuracy 0.015 - loss 0.040\n",
      "Epoch 134  -- accuracy 0.015 - loss 0.040\n",
      "Epoch 135  -- accuracy 0.015 - loss 0.040\n",
      "Epoch 136  -- accuracy 0.015 - loss 0.040\n",
      "Epoch 137  -- accuracy 0.015 - loss 0.039\n",
      "Epoch 138  -- accuracy 0.015 - loss 0.039\n",
      "Epoch 139  -- accuracy 0.015 - loss 0.039\n",
      "Epoch 140  -- accuracy 0.015 - loss 0.039\n",
      "Epoch 141  -- accuracy 0.015 - loss 0.039\n",
      "Epoch 142  -- accuracy 0.015 - loss 0.039\n",
      "Epoch 143  -- accuracy 0.015 - loss 0.039\n",
      "Epoch 144  -- accuracy 0.015 - loss 0.039\n",
      "Epoch 145  -- accuracy 0.015 - loss 0.039\n",
      "Epoch 146  -- accuracy 0.015 - loss 0.039\n",
      "Epoch 147  -- accuracy 0.015 - loss 0.039\n",
      "Epoch 148  -- accuracy 0.015 - loss 0.038\n",
      "Epoch 149  -- accuracy 0.015 - loss 0.038\n"
     ]
    }
   ],
   "source": [
    "# Learning rate\n",
    "\n",
    "code_dim=code_dims[1]\n",
    "batch_size=batch_sizes[1]\n",
    "\n",
    "for learning_rate in learning_rates[::2]:\n",
    "    autoencoder = Autoencoder(input_dim=flatten_dim, code_dim=code_dim, encoder_hidden_count=0, reduce_by=1.5)\n",
    "    optimizer = Optimizer(\n",
    "        autoencoder,\n",
    "        loss=MeanSquaredError(),\n",
    "        accuracy=Accuracy(),\n",
    "        learning_rate=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        epochs=150,\n",
    "    )\n",
    "\n",
    "    optimizer.fit(X_train, X_train)\n",
    "\n",
    "    pickle_results(code_dim, learning_rate, batch_size, optimizer, autoencoder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  -- accuracy 0.001 - loss 0.087\n",
      "Epoch 1  -- accuracy 0.004 - loss 0.048\n",
      "Epoch 2  -- accuracy 0.005 - loss 0.039\n",
      "Epoch 3  -- accuracy 0.008 - loss 0.035\n",
      "Epoch 4  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 5  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 6  -- accuracy 0.012 - loss 0.029\n",
      "Epoch 7  -- accuracy 0.013 - loss 0.028\n",
      "Epoch 8  -- accuracy 0.013 - loss 0.027\n",
      "Epoch 9  -- accuracy 0.012 - loss 0.027\n",
      "Epoch 10  -- accuracy 0.012 - loss 0.027\n",
      "Epoch 11  -- accuracy 0.011 - loss 0.027\n",
      "Epoch 12  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 13  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 14  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 15  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 16  -- accuracy 0.011 - loss 0.026\n",
      "Epoch 17  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 18  -- accuracy 0.012 - loss 0.026\n",
      "Epoch 19  -- accuracy 0.012 - loss 0.025\n",
      "Epoch 20  -- accuracy 0.012 - loss 0.025\n",
      "Epoch 21  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 22  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 23  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 24  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 25  -- accuracy 0.011 - loss 0.025\n",
      "Epoch 26  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 27  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 28  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 29  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 30  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 31  -- accuracy 0.011 - loss 0.024\n",
      "Epoch 32  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 33  -- accuracy 0.011 - loss 0.023\n",
      "Epoch 34  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 35  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 36  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 37  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 38  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 39  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 40  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 41  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 42  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 43  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 44  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 45  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 46  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 47  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 48  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 49  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 50  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 51  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 52  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 53  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 54  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 55  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 56  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 57  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 58  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 59  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 60  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 61  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 62  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 63  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 64  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 65  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 66  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 67  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 68  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 69  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 70  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 71  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 72  -- accuracy 0.012 - loss 0.023\n",
      "Epoch 73  -- accuracy 0.012 - loss 0.022\n",
      "Epoch 74  -- accuracy 0.012 - loss 0.022\n",
      "Epoch 75  -- accuracy 0.012 - loss 0.022\n",
      "Epoch 76  -- accuracy 0.012 - loss 0.022\n",
      "Epoch 77  -- accuracy 0.012 - loss 0.022\n",
      "Epoch 78  -- accuracy 0.012 - loss 0.022\n",
      "Epoch 79  -- accuracy 0.012 - loss 0.022\n",
      "Epoch 80  -- accuracy 0.012 - loss 0.022\n",
      "Epoch 81  -- accuracy 0.012 - loss 0.022\n",
      "Epoch 82  -- accuracy 0.012 - loss 0.022\n",
      "Epoch 83  -- accuracy 0.011 - loss 0.022\n",
      "Epoch 84  -- accuracy 0.011 - loss 0.022\n",
      "Epoch 85  -- accuracy 0.012 - loss 0.022\n",
      "Epoch 86  -- accuracy 0.012 - loss 0.022\n",
      "Epoch 87  -- accuracy 0.011 - loss 0.022\n",
      "Epoch 88  -- accuracy 0.011 - loss 0.022\n",
      "Epoch 89  -- accuracy 0.011 - loss 0.022\n",
      "Epoch 90  -- accuracy 0.011 - loss 0.022\n",
      "Epoch 91  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 92  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 93  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 94  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 95  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 96  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 97  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 98  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 99  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 100  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 101  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 102  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 103  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 104  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 105  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 106  -- accuracy 0.011 - loss 0.021\n",
      "Epoch 107  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 108  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 109  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 110  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 111  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 112  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 113  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 114  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 115  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 116  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 117  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 118  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 119  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 120  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 121  -- accuracy 0.012 - loss 0.021\n",
      "Epoch 122  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 123  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 124  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 125  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 126  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 127  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 128  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 129  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 130  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 131  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 132  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 133  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 134  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 135  -- accuracy 0.013 - loss 0.021\n",
      "Epoch 136  -- accuracy 0.013 - loss 0.020\n",
      "Epoch 137  -- accuracy 0.013 - loss 0.020\n",
      "Epoch 138  -- accuracy 0.013 - loss 0.020\n",
      "Epoch 139  -- accuracy 0.013 - loss 0.020\n",
      "Epoch 140  -- accuracy 0.014 - loss 0.020\n",
      "Epoch 141  -- accuracy 0.014 - loss 0.020\n",
      "Epoch 142  -- accuracy 0.014 - loss 0.020\n",
      "Epoch 143  -- accuracy 0.014 - loss 0.020\n",
      "Epoch 144  -- accuracy 0.014 - loss 0.020\n",
      "Epoch 145  -- accuracy 0.014 - loss 0.020\n",
      "Epoch 146  -- accuracy 0.014 - loss 0.020\n",
      "Epoch 147  -- accuracy 0.014 - loss 0.020\n",
      "Epoch 148  -- accuracy 0.014 - loss 0.020\n",
      "Epoch 149  -- accuracy 0.014 - loss 0.020\n",
      "Epoch 0  -- accuracy 0.001 - loss 0.180\n",
      "Epoch 1  -- accuracy 0.002 - loss 0.141\n",
      "Epoch 2  -- accuracy 0.002 - loss 0.116\n",
      "Epoch 3  -- accuracy 0.002 - loss 0.098\n",
      "Epoch 4  -- accuracy 0.002 - loss 0.086\n",
      "Epoch 5  -- accuracy 0.002 - loss 0.079\n",
      "Epoch 6  -- accuracy 0.003 - loss 0.074\n",
      "Epoch 7  -- accuracy 0.003 - loss 0.071\n",
      "Epoch 8  -- accuracy 0.003 - loss 0.069\n",
      "Epoch 9  -- accuracy 0.003 - loss 0.067\n",
      "Epoch 10  -- accuracy 0.003 - loss 0.066\n",
      "Epoch 11  -- accuracy 0.003 - loss 0.065\n",
      "Epoch 12  -- accuracy 0.003 - loss 0.064\n",
      "Epoch 13  -- accuracy 0.003 - loss 0.063\n",
      "Epoch 14  -- accuracy 0.003 - loss 0.062\n",
      "Epoch 15  -- accuracy 0.003 - loss 0.061\n",
      "Epoch 16  -- accuracy 0.003 - loss 0.059\n",
      "Epoch 17  -- accuracy 0.003 - loss 0.058\n",
      "Epoch 18  -- accuracy 0.003 - loss 0.057\n",
      "Epoch 19  -- accuracy 0.002 - loss 0.056\n",
      "Epoch 20  -- accuracy 0.002 - loss 0.055\n",
      "Epoch 21  -- accuracy 0.002 - loss 0.054\n",
      "Epoch 22  -- accuracy 0.002 - loss 0.053\n",
      "Epoch 23  -- accuracy 0.002 - loss 0.052\n",
      "Epoch 24  -- accuracy 0.002 - loss 0.051\n",
      "Epoch 25  -- accuracy 0.002 - loss 0.050\n",
      "Epoch 26  -- accuracy 0.002 - loss 0.049\n",
      "Epoch 27  -- accuracy 0.002 - loss 0.049\n",
      "Epoch 28  -- accuracy 0.003 - loss 0.048\n",
      "Epoch 29  -- accuracy 0.003 - loss 0.048\n",
      "Epoch 30  -- accuracy 0.004 - loss 0.047\n",
      "Epoch 31  -- accuracy 0.005 - loss 0.047\n",
      "Epoch 32  -- accuracy 0.006 - loss 0.047\n",
      "Epoch 33  -- accuracy 0.008 - loss 0.046\n",
      "Epoch 34  -- accuracy 0.009 - loss 0.046\n",
      "Epoch 35  -- accuracy 0.009 - loss 0.046\n",
      "Epoch 36  -- accuracy 0.010 - loss 0.046\n",
      "Epoch 37  -- accuracy 0.011 - loss 0.046\n",
      "Epoch 38  -- accuracy 0.011 - loss 0.045\n",
      "Epoch 39  -- accuracy 0.010 - loss 0.045\n",
      "Epoch 40  -- accuracy 0.010 - loss 0.045\n",
      "Epoch 41  -- accuracy 0.010 - loss 0.045\n",
      "Epoch 42  -- accuracy 0.010 - loss 0.045\n",
      "Epoch 43  -- accuracy 0.009 - loss 0.045\n",
      "Epoch 44  -- accuracy 0.009 - loss 0.045\n",
      "Epoch 45  -- accuracy 0.009 - loss 0.044\n",
      "Epoch 46  -- accuracy 0.009 - loss 0.044\n",
      "Epoch 47  -- accuracy 0.008 - loss 0.044\n",
      "Epoch 48  -- accuracy 0.008 - loss 0.044\n",
      "Epoch 49  -- accuracy 0.008 - loss 0.044\n",
      "Epoch 50  -- accuracy 0.008 - loss 0.043\n",
      "Epoch 51  -- accuracy 0.007 - loss 0.043\n",
      "Epoch 52  -- accuracy 0.007 - loss 0.043\n",
      "Epoch 53  -- accuracy 0.007 - loss 0.043\n",
      "Epoch 54  -- accuracy 0.007 - loss 0.043\n",
      "Epoch 55  -- accuracy 0.007 - loss 0.043\n",
      "Epoch 56  -- accuracy 0.007 - loss 0.042\n",
      "Epoch 57  -- accuracy 0.007 - loss 0.042\n",
      "Epoch 58  -- accuracy 0.007 - loss 0.042\n",
      "Epoch 59  -- accuracy 0.006 - loss 0.042\n",
      "Epoch 60  -- accuracy 0.006 - loss 0.042\n",
      "Epoch 61  -- accuracy 0.006 - loss 0.041\n",
      "Epoch 62  -- accuracy 0.007 - loss 0.041\n",
      "Epoch 63  -- accuracy 0.006 - loss 0.041\n",
      "Epoch 64  -- accuracy 0.006 - loss 0.041\n",
      "Epoch 65  -- accuracy 0.007 - loss 0.041\n",
      "Epoch 66  -- accuracy 0.007 - loss 0.040\n",
      "Epoch 67  -- accuracy 0.006 - loss 0.040\n",
      "Epoch 68  -- accuracy 0.006 - loss 0.040\n",
      "Epoch 69  -- accuracy 0.006 - loss 0.040\n",
      "Epoch 70  -- accuracy 0.007 - loss 0.040\n",
      "Epoch 71  -- accuracy 0.006 - loss 0.039\n",
      "Epoch 72  -- accuracy 0.007 - loss 0.039\n",
      "Epoch 73  -- accuracy 0.007 - loss 0.039\n",
      "Epoch 74  -- accuracy 0.007 - loss 0.039\n",
      "Epoch 75  -- accuracy 0.007 - loss 0.039\n",
      "Epoch 76  -- accuracy 0.007 - loss 0.038\n",
      "Epoch 77  -- accuracy 0.007 - loss 0.038\n",
      "Epoch 78  -- accuracy 0.007 - loss 0.038\n",
      "Epoch 79  -- accuracy 0.007 - loss 0.038\n",
      "Epoch 80  -- accuracy 0.008 - loss 0.038\n",
      "Epoch 81  -- accuracy 0.007 - loss 0.037\n",
      "Epoch 82  -- accuracy 0.008 - loss 0.037\n",
      "Epoch 83  -- accuracy 0.008 - loss 0.037\n",
      "Epoch 84  -- accuracy 0.007 - loss 0.037\n",
      "Epoch 85  -- accuracy 0.008 - loss 0.037\n",
      "Epoch 86  -- accuracy 0.007 - loss 0.037\n",
      "Epoch 87  -- accuracy 0.008 - loss 0.036\n",
      "Epoch 88  -- accuracy 0.008 - loss 0.036\n",
      "Epoch 89  -- accuracy 0.008 - loss 0.036\n",
      "Epoch 90  -- accuracy 0.008 - loss 0.036\n",
      "Epoch 91  -- accuracy 0.008 - loss 0.036\n",
      "Epoch 92  -- accuracy 0.008 - loss 0.035\n",
      "Epoch 93  -- accuracy 0.008 - loss 0.035\n",
      "Epoch 94  -- accuracy 0.008 - loss 0.035\n",
      "Epoch 95  -- accuracy 0.008 - loss 0.035\n",
      "Epoch 96  -- accuracy 0.009 - loss 0.035\n",
      "Epoch 97  -- accuracy 0.009 - loss 0.035\n",
      "Epoch 98  -- accuracy 0.009 - loss 0.035\n",
      "Epoch 99  -- accuracy 0.009 - loss 0.034\n",
      "Epoch 100  -- accuracy 0.009 - loss 0.034\n",
      "Epoch 101  -- accuracy 0.009 - loss 0.034\n",
      "Epoch 102  -- accuracy 0.009 - loss 0.034\n",
      "Epoch 103  -- accuracy 0.009 - loss 0.034\n",
      "Epoch 104  -- accuracy 0.009 - loss 0.034\n",
      "Epoch 105  -- accuracy 0.009 - loss 0.034\n",
      "Epoch 106  -- accuracy 0.009 - loss 0.034\n",
      "Epoch 107  -- accuracy 0.009 - loss 0.033\n",
      "Epoch 108  -- accuracy 0.009 - loss 0.033\n",
      "Epoch 109  -- accuracy 0.009 - loss 0.033\n",
      "Epoch 110  -- accuracy 0.009 - loss 0.033\n",
      "Epoch 111  -- accuracy 0.010 - loss 0.033\n",
      "Epoch 112  -- accuracy 0.009 - loss 0.033\n",
      "Epoch 113  -- accuracy 0.009 - loss 0.033\n",
      "Epoch 114  -- accuracy 0.010 - loss 0.033\n",
      "Epoch 115  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 116  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 117  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 118  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 119  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 120  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 121  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 122  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 123  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 124  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 125  -- accuracy 0.010 - loss 0.032\n",
      "Epoch 126  -- accuracy 0.010 - loss 0.031\n",
      "Epoch 127  -- accuracy 0.010 - loss 0.031\n",
      "Epoch 128  -- accuracy 0.010 - loss 0.031\n",
      "Epoch 129  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 130  -- accuracy 0.010 - loss 0.031\n",
      "Epoch 131  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 132  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 133  -- accuracy 0.010 - loss 0.031\n",
      "Epoch 134  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 135  -- accuracy 0.010 - loss 0.031\n",
      "Epoch 136  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 137  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 138  -- accuracy 0.010 - loss 0.031\n",
      "Epoch 139  -- accuracy 0.011 - loss 0.031\n",
      "Epoch 140  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 141  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 142  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 143  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 144  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 145  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 146  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 147  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 148  -- accuracy 0.011 - loss 0.030\n",
      "Epoch 149  -- accuracy 0.011 - loss 0.030\n"
     ]
    }
   ],
   "source": [
    "# Batch size\n",
    "\n",
    "code_dim=code_dims[1]\n",
    "learning_rate=learning_rates[1]\n",
    "\n",
    "for batch_size in batch_sizes[::2]:\n",
    "    autoencoder = Autoencoder(input_dim=flatten_dim, code_dim=code_dim, encoder_hidden_count=0, reduce_by=1.5)\n",
    "    optimizer = Optimizer(\n",
    "        autoencoder,\n",
    "        loss=MeanSquaredError(),\n",
    "        accuracy=Accuracy(),\n",
    "        learning_rate=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        epochs=150,\n",
    "    )\n",
    "    \n",
    "    optimizer.fit(X_train, X_train)\n",
    "\n",
    "    pickle_results(code_dim, learning_rate, batch_size, optimizer, autoencoder)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularisation techniques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Injecting noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 784))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset.dataset import load_fashion_mnist_dataset\n",
    "\n",
    "noisy_X_train, X_train = load_fashion_mnist_dataset(noisy=True, noise_level=0.08)\n",
    "\n",
    "noisy_X_train.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaR0lEQVR4nO2deYxdZ3nGn/duM3NnH489XhPHjmPsksQJJoQmUFoCTULVJCoQUomGKsWgggoSrYqoVCJUtagqUEoprQkRoQpbRCCBhiUEojQtiyfBJE7s2I7jfRlvs8/c9e0fc0NN4u8501nuHfV7ftJoZs4z3znfPfc899y57/e+r7k7hBD//0k1egJCiPogswsRCTK7EJEgswsRCTK7EJGQqefBcpm8t+S6wn+QEBmo5tJBzSoJUYWU8X2nue7kZdGqCYcuJ/xBwtQLi/jcUCV6NuHYlYR9J8ipDN9/tRI+cZlMhY4tl8PPNwBkhvnk0sXw3KxQpmO9OUv1pGs16XqsNJPHlnTOS+F9T06eRbE4dt49zMrsZnY9gE8DSAO4y90/zv6+JdeFq1/x7vD+SvzJH7+gI6jlBot0bJWdXACFLv7kllvCz0Bmgj+xzWf43FIF/rh3/1Ez1dMTYUN5X4GOrY4mXNQJZs53T1B9YrQpqPX2jtCxJ090Un3pw/zybTscfuy5fSfo2MK6pVRPlfh5SQ9NUn14Y1dQYzcWAMgfD19P/f2fDWozfhtvZmkAnwVwA4CNAG4zs40z3Z8QYn6Zzf/sVwHY6+773L0I4KsAbpqbaQkh5prZmH0FgEPn/H64tu3XMLMtZtZvZv3F8vgsDieEmA3z/mm8u291983uvjmXyc/34YQQAWZj9iMAVp3z+8raNiHEAmQ2Zt8GYJ2ZXWRmOQDvAPDg3ExLCDHXzDj05u5lM3s/gO9jKvR2t7s/w8ZUsykUloTfypfaeHisbR8P1TDGVrVQncVkAaDnscNhMctPY2lZF9UHXtVG9bt+99+oPlYNh7eWZobo2CcnVlP9Ta3PUX1/mYfHLs8NB7X+Qg8d+5OVF1P9keXrqZ79UDisWO0Oh3GB5NBapYlfq+Xl/DltGgzH+ZuOjvJjd5JQLIn/zyrO7u4PAXhoNvsQQtQHLZcVIhJkdiEiQWYXIhJkdiEiQWYXIhJkdiEioa757KlSlcYQxzd10fHl9nA8eWx5WAOAtsM85TCJkc0vW/b/K8rN/DUzfyIhxbXMU2SfnVxJ9QpJgH5q4gI+NiGfcsueP6T6axbtp/quprNBrT3F02OfOMvnfmR/L9U7CieDWrWHx8FTkyWqj1zI0447d/I1IdV8eA3A2MV8DUCOxOhh4WtBd3YhIkFmFyISZHYhIkFmFyISZHYhIkFmFyIS6hp6mzpi+PWl+2mejsnCCrlh/lCSqn2OX8TDHYzu/yLpr0Bi2eHCay6kej7FK8Te2Lo3qD0wytNAHzp5KdX3HVhC9bPjPHX49SueD2pp8DTSty/dRvXvZHhIc2DdmqBmVf6ceELp8Z6fHqd6ubed6sXOcOgtN8TLXI8tywW1SlahNyGiR2YXIhJkdiEiQWYXIhJkdiEiQWYXIhJkdiEiob5xdnfYRDg2Wm3naYMszm4JbY9LvbwbTevP91O9cmFfeN+rFvGxLfw0l/N88nd08pjuzXv+IKit7+DdSi/r5H097rv+21T/3OA6qv/w5Iag9talT9CxH/v226ieXzdI9Y58+F7WfJqnsJZbE0pFJ8TRy+3hWDgANJ0Kr/vwdMI9OKGlcwjd2YWIBJldiEiQ2YWIBJldiEiQ2YWIBJldiEiQ2YWIhLrG2atNaYyv7Q7qqYS2yZOLwjnArUd5znd6gsdVC7+xiurNzw8EtYl1POc7VeFx9GI3f9xXb38r1a9bHm6rfF077aKNP/7RHVS/v/tyqk+c4usXXnf5rqB2oMBLQf/zLXdT/b5Tr6b6wYHwGoDcodN07Og1y6meO5twn0xa99EVLn2eO8NrL7QdDOus9fiszG5m+wGMAKgAKLv75tnsTwgxf8zFnf233f3UHOxHCDGP6H92ISJhtmZ3AD8wsyfMbMv5/sDMtphZv5n1l4pjszycEGKmzPZt/LXufsTMlgB42Mx2uftj5/6Bu28FsBUA2rtWJnxsIYSYL2Z1Z3f3I7XvAwC+CeCquZiUEGLumbHZzazVzNpf/BnAmwHsmKuJCSHmltm8je8D8E2byjHPAPiyu3+PDUgVq2g5GG5lO3pJJz1gdjwcQyx1JNSNH+c1xpNyhIdfFY67tu8KtyUGgLG1XVTPDvHX3I9d8gDVv3bqNUHt6yX+Zutr1/0L1b87zOPsX5oMHxsAOjLh9Q/DZV6/oH/8Iqo/eYK3sl5SqgS1yTWL6dg0X5aBahPPd8+MJ+0g/B+tFXnd+MFLw7n0lWfD19KMze7u+wDwK0EIsWBQ6E2ISJDZhYgEmV2ISJDZhYgEmV2ISKh/KWnSvrj1wCgdPrQ+HHJoGgqHWQDAdr7A5/bacMljAMiQsF+1NZyuCADpCT63pjP8abjr+OupXq6GX7Pfu/xROvaHI6+k+rLcINV//PrPUP3JwtKgtr/IU1x3ji2j+tg4P+/VDCs9zhdzJrVNrqZ5rDaV0PK52BOe+0RvGx3bvXsiqKUL4etUd3YhIkFmFyISZHYhIkFmFyISZHYhIkFmFyISZHYhIqGucXbPpFDqbgnqE308btp6LJymmjs6TMeWr7iE6/mEFr0t4ddFK/P2vJ7hr6k9u3g65K1LtlH93uPhNNP7TvMU11+e4iWTUwm9sJes4+f9SClcOrzk/JxnjZfYLo2FS4sDwNjK8OVdyfE4eOtx/pw0H+GPe3xNF9WdxOHbD/Ky6FYh54U8XbqzCxEJMrsQkSCzCxEJMrsQkSCzCxEJMrsQkSCzCxEJ9c1nrwLpQji3u2PXIB1eaQ/H4Ycu57nR5SYeV+3Yz9vk5s6GA5jZgXB5bAAYX9dD9dYnD1F9Y+441d+y+Omg9vQ4L7d86aJjVP/pA5dR/f7uK6leroZj6eMJ6xPeu+JRqj98gh+bxaPzAwk1BgbGqV5awnPOJ7v5GoJ0IXw95Q+G89WBhHUbJE9fd3YhIkFmFyISZHYhIkFmFyISZHYhIkFmFyISZHYhIqG++exZw+SScJvelkM8h7jYGY7LZiZ47nPnjkGqj6/m7aJZS+fCokV0aOsLPPd5+OoLqf7dUV7b/USpI6itbj5Fxz46up7q5TzPZ//Pp/j4iy8OrxHoa+HrE/6s/1aqlxbxWLmnw/eyVJFfL0k1CApdPJe+cy+P0xe7wmtGCn2tdCyrh+97yGOmewVgZneb2YCZ7ThnW4+ZPWxme2rfwxUKhBALgum8jf8igOtfsu3DAB5x93UAHqn9LoRYwCSa3d0fA3DmJZtvAnBP7ed7ANw8t9MSQsw1M/2Ars/dX1xUfRxAX+gPzWyLmfWbWX+pODbDwwkhZsusP413dwcpc+fuW919s7tvzub4Bw9CiPljpmY/YWbLAKD2fWDupiSEmA9mavYHAdxe+/l2AA/MzXSEEPNFYpzdzL4C4A0Aes3sMICPAvg4gK+b2R0ADgB4+7SOVgVSpH/0xIpw/3UAyEyG46rNx3hv92oLj4u27jpJ9eKqcHQxd+gsP3Z7uFY+AFiVx7KPFLqovqr5pZ+f/i//+szr6NhPXHkf1f/60Bqqn1lCZbxr5X8HtQMFXoPgb3/zO1S/5W/+guptB8Kx7swQzxkv9eSpbjzEj1Ibv94YmTHeG95Z3/lK+FpKNLu73xaQ3pg0VgixcNByWSEiQWYXIhJkdiEiQWYXIhJkdiEiob6lpAGwLry5wXBLZoCXBi4t4qGSQjcPhbTk+KmwcjikwcJyAFBs58due5anoe4cXkr150aCq5Vx6/on6dgseAwpzbsH4/JXHKT69rELgtqpIi/H/Kdn3kb1hI7OGF8eTqfOdPMy1vm94XAmAJQ6eHnwppM8xXVoQzilmqWwAkDzAAkbqmWzEEJmFyISZHYhIkFmFyISZHYhIkFmFyISZHYhIqG+cXbj6Xme4689k93h8rue4rHJ/P0/o3rhxldTfawvfKq6d/N0yabTCcHqDG/vm0RPU7jc1zPDy+jY3+/4BdU7DvK5Hx/jacnNmXB58M4sP2+5FE/1rDTz57yaDeuVKr/Wzr5qMdW7nh6kejGhHHTzqfB5mezl6zIy4+E1AswHurMLEQkyuxCRILMLEQkyuxCRILMLEQkyuxCRILMLEQl1jbNbuYrc6XBsdXBDQsz2bDj3utDJX7eqr7uC6km59JmJ8LHPvIKXil7cP0j1wrJwy2UAGJ/kidu/1bsnqHVneMut4xV+7OzZSaoPvMDbVV93zXNB7d5fXEXHfv93/onq7xz6c6o3nQ3H6VnJZQAotvN899QQL11ui3l9hexI+HrLDfFrcWR1eN9sHYvu7EJEgswuRCTI7EJEgswuRCTI7EJEgswuRCTI7EJEQl3j7J5JoUDij+UWnp9cGQu/NrXv57nRlWb+UCeXhXPlAaDlZDj22TzE4+ATy3l99GqOP253rv/kTLit8kiJP65PrOUtm1Hmj806eEy4ORXO275iLa85f+fh36N6945hqldbws/50MU8Dt6ekMc/sT5cqx8AcgnrE5AKX8uFHv6cNZ8h6wdIf4PEO7uZ3W1mA2a245xtd5rZETPbXvu6MWk/QojGMp238V8EcP15tn/K3TfVvh6a22kJIeaaRLO7+2MAeC8cIcSCZzYf0L3fzJ6qvc0PNjszsy1m1m9m/aUiX6cthJg/Zmr2zwFYC2ATgGMAPhH6Q3ff6u6b3X1zNseL8Akh5o8Zmd3dT7h7xd2rAD4PgKcvCSEazozMbmbn1ie+BcCO0N8KIRYGiXF2M/sKgDcA6DWzwwA+CuANZrYJU92g9wN4z3QOZhVHbjAcv+wsJTTcJinInuWvW0l52SnS+x0ARlaGY5/th3lMNjPIjz25lP97c0HHWaq3Z8LHX54fomN3l5ZQvdLBY775p3gu/y2vC9elLzmvlz9Z5fXTD62+hOpWDV8wi57gnzkPb+iiev4of06H1vPaDJnJ8Nw6fnGcjj1zdbgXAKuVn2h2d7/tPJu/kDROCLGw0HJZISJBZhciEmR2ISJBZhciEmR2ISKhvi2bAYCEQ0ptPBSTKoXHFpv4Q2kdC6daAkB6nLcHbhoOh4GSxlYT5lbo5vrOkzydcvOyQ0HtVIGH9R4d2kD1JIodvCTz3x29IagNl5rp2FuXbqP6o+2vpTpLU/Usv9ZYSjMADK/hIcdKQtpy+4Fw6K6yiIfturedCGoZcp3rzi5EJMjsQkSCzC5EJMjsQkSCzC5EJMjsQkSCzC5EJNQ3zp4yVPLheHX+KC8HnRoLx03HV3fSscUunqo5sZinU7YfCM9taB2PZTeRVtMAXz8AAJO7+WNrXfl8UFubP0nHJqWZ7knxeHFxCV9j0JUNn7ey83vNgUIv1Tv3jFMdZO7FnoQ4eTOfW1IZ69GLeKx8bEV4jUH7nhE6trQ0fD34sfDzqTu7EJEgswsRCTK7EJEgswsRCTK7EJEgswsRCTK7EJFQ3zi7O8xJTnpnjg4nVXKR/8leOnbsmnVUz43wUtLVpnD8smMfj/emT49SfWw9jydjFV9/UKiGn8Yv795Mx37miq9Q/afFK6nedJy3Ph4shePZN/eGy0wDwE9H11I9k3BehzYtDmop0toYANr28Vj30PoOqnfu4iW8GRMreItvT4eNwDTd2YWIBJldiEiQ2YWIBJldiEiQ2YWIBJldiEiQ2YWIhLrG2avZFCZ6w7H01kM8Xm2kpXPpstV0bH4/zz9OjfFYNqrhY5f7uvjQLp7v3nJkjOp2kMd0Ry4M5+pftuwoHTtW5Xn+k30877v1CI9XX9fzbFD71qkr6NhnBpZSvWMTPy+th0kufZ5f+kn57s2neR+C8VU8n715IDy3/PO8RbeVwjUEUpNEo3sFYGarzOzHZvasmT1jZh+obe8xs4fNbE/te3fSvoQQjWM6b+PLAD7k7hsBXA3gfWa2EcCHATzi7usAPFL7XQixQEk0u7sfc/cnaz+PANgJYAWAmwDcU/uzewDcPE9zFELMAf+nD+jMbDWAKwD8DECfux+rSccBnLchmZltMbN+M+svFfhaZiHE/DFts5tZG4BvAPigu//ap13u7gDO+0mNu291983uvjnbxBf4CyHmj2mZ3cyymDL6ve5+f23zCTNbVtOXARiYnykKIeaCxNCbmRmALwDY6e6fPEd6EMDtAD5e+/5A0r5SxSryx8KtaksJ5Z4zI+FwR7mFP5RyQtqgOderJL+26WT4MQHJqbvNh3g6ZOduKmPDDceD2ukSD/v9aHgj1TNjvAx22zEq43unXxnUPrriO3TsP2bfSPVf5DdRPT0cLj2ePc7P+fgl4fRYAMjv5iW6Ry5bQvUzrwxfb70/52G94vJwyNEHwj6YTpz9GgDvBPC0mW2vbfsIpkz+dTO7A8ABAG+fxr6EEA0i0ezu/jiA0G2Nv/QKIRYMWi4rRCTI7EJEgswuRCTI7EJEgswuRCTUvWUzK8nMYtkAYJVwmmlmjLcOzp7maaQwfuxyVzjl0XiWJ1qeO0H1yhLekjmpzPXhyXDC4WVth+nYxRme+rujehnVE7ou4/pFO4LaXaevpWMPjPZQvf1gkerFJeE1BplxvvbB+eWAwVedd3X4r0h6zhY/Fl4bkZQSnRklcfhK+GLUnV2ISJDZhYgEmV2ISJDZhYgEmV2ISJDZhYgEmV2ISKhrnL2SNYwuD8c3mwd57nQ1F47RFzuzdKxVeWvhQndC3DV8aLTtPE3HDr96BdXLTTyomz/B85v7msKx8k9tu46OvWrdC1TPHeV536kirwPQlQ6XBx8s8efk+f4LqL4yy89L7mw4nz01mTA2ze+DmUmu5w4PUh3ZsPVSY+F5A8DEBeF1GZ5Ry2YhokdmFyISZHYhIkFmFyISZHYhIkFmFyISZHYhIqGucXarAtlxkm9b4onhZ9eHc8q7d/Pa7dn9vIfFZO9KqrftGQyPXc0b2FZJjB4A8gM85lvo4U9TZyYcy/6TKx+nY791iOerd/bxOHpuP6+f/qVjrw1qS1tG6Fjjyy7gKb4+IVUI1zgodzTTsWnS+hgAMrt5jYLSRn49DV8YPn52nOfCdzx1KqilCuGTpju7EJEgswsRCTK7EJEgswsRCTK7EJEgswsRCTK7EJEwnf7sqwB8CUAfAAew1d0/bWZ3Ang3gBcDrR9x94fYvlKlKlqOh+PhZzfw/OaufeE836G1PG7a0sXjnuO9PBieHW0ParkzPMZfyfHHZaTWNwB0PhGuMQ4A/3H00qC2sZuPPX2Gx9EXDU1QfeTK5VSvlI8EtTt6H6Njf773CqqnEs5baji8/gDtTXTs4Cv4eUmv4Xrndr7+ILcoXD+hYzuP4U+sWRTUqkfD1/F0FtWUAXzI3Z80s3YAT5jZwzXtU+7+D9PYhxCiwUynP/sxAMdqP4+Y2U4AvPSKEGLB8X/6n93MVgO4AsDPapveb2ZPmdndZnbeNaNmtsXM+s2sv1RKaMEkhJg3pm12M2sD8A0AH3T3YQCfA7AWwCZM3fk/cb5x7r7V3Te7++ZslvewEkLMH9Myu5llMWX0e939fgBw9xPuXnH3KoDPA7hq/qYphJgtiWY3MwPwBQA73f2T52xfds6f3QIg3K5TCNFwpvNp/DUA3gngaTPbXtv2EQC3mdkmTIXj9gN4T9KOqlnDZF845NG1m4d5Su3hctG9D+yiY8sbL0yYGw/FpCfDqYOTS8KptwCQG+SthSeW8mNXc4upnk2HQzWtaV6WeMMqHpobXrOK6klppm/pC98DDpV5S+ZSO993epynoQ5vWhrUWgb4eWk/xPXswCjVC6u6qM5aXY9cuiRhbPi8eDqsTefT+McBnG8PNKYuhFhYaAWdEJEgswsRCTK7EJEgswsRCTK7EJEgswsRCXUtJQ1gKiofICnVk700lTfw9r7VLH9da9vNWxOPX9QR1LKjPN7rGX7spjN8fKrCSwvv3bMsqL0wwlN7193LH7dfxGPdlSzXP/n4m4Na62KSggpg+TauW8J56egPp9eOXRo+ZwDQdIqnLU+uCF8PAFDN8ec8fyS8/0IvX3fRfDI8NlUKnxPd2YWIBJldiEiQ2YWIBJldiEiQ2YWIBJldiEiQ2YWIBHNPiG3P5cHMTgI4cM6mXgDh/rONZaHObaHOC9DcZspczu1Cdz9vAYS6mv1lBzfrd/fNDZsAYaHObaHOC9DcZkq95qa38UJEgswuRCQ02uxbG3x8xkKd20KdF6C5zZS6zK2h/7MLIepHo+/sQog6IbMLEQkNMbuZXW9mz5nZXjP7cCPmEMLM9pvZ02a23cz6GzyXu81swMx2nLOtx8weNrM9te/n7bHXoLndaWZHauduu5nd2KC5rTKzH5vZs2b2jJl9oLa9oeeOzKsu563u/7ObWRrAbgBvAnAYwDYAt7n7s3WdSAAz2w9gs7s3fAGGmb0ewCiAL7n7K2vb/h7AGXf/eO2Fstvd/3KBzO1OAKONbuNd61a07Nw24wBuBvAuNPDckXm9HXU4b424s18FYK+773P3IoCvAripAfNY8Lj7YwDOvGTzTQDuqf18D6YulroTmNuCwN2PufuTtZ9HALzYZryh547Mqy40wuwrABw65/fDWFj93h3AD8zsCTPb0ujJnIc+dz9W+/k4gL5GTuY8JLbxricvaTO+YM7dTNqfzxZ9QPdyrnX3KwHcAOB9tberCxKf+h9sIcVOp9XGu16cp834r2jkuZtp+/PZ0gizHwFwbrfAlbVtCwJ3P1L7PgDgm1h4rahPvNhBt/Z9oMHz+RULqY33+dqMYwGcu0a2P2+E2bcBWGdmF5lZDsA7ADzYgHm8DDNrrX1wAjNrBfBmLLxW1A8CuL328+0AHmjgXH6NhdLGO9RmHA0+dw1vf+7udf8CcCOmPpF/HsBfNWIOgXmtAfDL2tczjZ4bgK9g6m1dCVOfbdwBYBGARwDsAfBDAD0LaG7/DuBpAE9hyljLGjS3azH1Fv0pANtrXzc2+tyRedXlvGm5rBCRoA/ohIgEmV2ISJDZhYgEmV2ISJDZhYgEmV2ISJDZhYiE/wFv5hokcr900gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from numpy import random\n",
    "\n",
    "random_idx = random.randint(0,noisy_X_train.shape[0])\n",
    "\n",
    "plt.imshow(noisy_X_train[random_idx].reshape(28, 28), interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(X_train[random_idx].reshape(28, 28), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/olga/projects/sem7/neural_networks_course/autoencoder_experiment.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/olga/projects/sem7/neural_networks_course/autoencoder_experiment.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m MeanSquaredError\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/olga/projects/sem7/neural_networks_course/autoencoder_experiment.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m autoencoder \u001b[39m=\u001b[39m Autoencoder(input_dim\u001b[39m=\u001b[39mflatten_dim, code_dim\u001b[39m=\u001b[39m\u001b[39m108\u001b[39m, encoder_hidden_count\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, reduce_by\u001b[39m=\u001b[39m\u001b[39m1.5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/olga/projects/sem7/neural_networks_course/autoencoder_experiment.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m optimizer \u001b[39m=\u001b[39m Optimizer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/olga/projects/sem7/neural_networks_course/autoencoder_experiment.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     autoencoder,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/olga/projects/sem7/neural_networks_course/autoencoder_experiment.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     loss\u001b[39m=\u001b[39mMeanSquaredError(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/olga/projects/sem7/neural_networks_course/autoencoder_experiment.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/olga/projects/sem7/neural_networks_course/autoencoder_experiment.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/olga/projects/sem7/neural_networks_course/autoencoder_experiment.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m optimizer\u001b[39m.\u001b[39mfit(X_train, X_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from models.metrics import MeanSquaredError\n",
    "from models.neural_network import Autoencoder\n",
    "from models.optimizer import Optimizer\n",
    "\n",
    "autoencoder = Autoencoder(input_dim=flatten_dim, code_dim=108, encoder_hidden_count=1, reduce_by=1.5)\n",
    "optimizer = Optimizer(\n",
    "    autoencoder,\n",
    "    loss=MeanSquaredError(),\n",
    "    learning_rate=0.9,\n",
    "    batch_size=128,\n",
    "    epochs=500,\n",
    ")\n",
    "    \n",
    "optimizer.fit(noisy_X_train, X_train)\n",
    "\n",
    "path = \"saved_models/networks/regularisation/noise\"\n",
    "\n",
    "with open(f\"{path}/autoencoder\", 'wb') as pickle_file:\n",
    "    pickle.dump(autoencoder, pickle_file)\n",
    "\n",
    "with open(f\"{path}/optimizer\", 'wb') as pickle_file:\n",
    "    pickle.dump(optimizer, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
