{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 00:30:15.026110: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-10 00:30:15.085002: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-10 00:30:15.085712: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-10 00:30:16.182820: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset.dataset import load_fashion_mnist_dataset\n",
    "\n",
    "X_train, X_test = load_fashion_mnist_dataset()\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_dim = X_train[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from models.optimizer import Optimizer\n",
    "from models.neural_network import Autoencoder\n",
    "\n",
    "def pickle_results(optimizer: Optimizer, autoencoder: Autoencoder):\n",
    "    with open(f\"saved_models/networks/autoencoder_best\", 'wb') as pickle_file:\n",
    "        pickle.dump(autoencoder, pickle_file)\n",
    "\n",
    "    with open(f\"saved_models/optimizers/optimizer_best\", 'wb') as pickle_file:\n",
    "        pickle.dump(optimizer, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  --  loss 0.069\n",
      "Epoch 1  --  loss 0.045\n",
      "Epoch 2  --  loss 0.041\n",
      "Epoch 3  --  loss 0.036\n",
      "Epoch 4  --  loss 0.031\n",
      "Epoch 5  --  loss 0.029\n",
      "Epoch 6  --  loss 0.027\n",
      "Epoch 7  --  loss 0.026\n",
      "Epoch 8  --  loss 0.025\n",
      "Epoch 9  --  loss 0.025\n",
      "Epoch 10  --  loss 0.024\n",
      "Epoch 11  --  loss 0.023\n",
      "Epoch 12  --  loss 0.023\n",
      "Epoch 13  --  loss 0.022\n",
      "Epoch 14  --  loss 0.022\n",
      "Epoch 15  --  loss 0.022\n",
      "Epoch 16  --  loss 0.021\n",
      "Epoch 17  --  loss 0.021\n",
      "Epoch 18  --  loss 0.020\n",
      "Epoch 19  --  loss 0.020\n",
      "Epoch 20  --  loss 0.020\n",
      "Epoch 21  --  loss 0.019\n",
      "Epoch 22  --  loss 0.019\n",
      "Epoch 23  --  loss 0.019\n",
      "Epoch 24  --  loss 0.019\n",
      "Epoch 25  --  loss 0.018\n",
      "Epoch 26  --  loss 0.018\n",
      "Epoch 27  --  loss 0.018\n",
      "Epoch 28  --  loss 0.018\n",
      "Epoch 29  --  loss 0.017\n",
      "Epoch 30  --  loss 0.017\n",
      "Epoch 31  --  loss 0.017\n",
      "Epoch 32  --  loss 0.017\n",
      "Epoch 33  --  loss 0.017\n",
      "Epoch 34  --  loss 0.016\n",
      "Epoch 35  --  loss 0.016\n",
      "Epoch 36  --  loss 0.016\n",
      "Epoch 37  --  loss 0.016\n",
      "Epoch 38  --  loss 0.016\n",
      "Epoch 39  --  loss 0.016\n",
      "Epoch 40  --  loss 0.015\n",
      "Epoch 41  --  loss 0.015\n",
      "Epoch 42  --  loss 0.015\n",
      "Epoch 43  --  loss 0.015\n",
      "Epoch 44  --  loss 0.015\n",
      "Epoch 45  --  loss 0.015\n",
      "Epoch 46  --  loss 0.015\n",
      "Epoch 47  --  loss 0.014\n",
      "Epoch 48  --  loss 0.014\n",
      "Epoch 49  --  loss 0.014\n",
      "Epoch 50  --  loss 0.014\n",
      "Epoch 51  --  loss 0.014\n",
      "Epoch 52  --  loss 0.014\n",
      "Epoch 53  --  loss 0.014\n",
      "Epoch 54  --  loss 0.014\n",
      "Epoch 55  --  loss 0.014\n",
      "Epoch 56  --  loss 0.014\n",
      "Epoch 57  --  loss 0.013\n",
      "Epoch 58  --  loss 0.013\n",
      "Epoch 59  --  loss 0.013\n",
      "Epoch 60  --  loss 0.013\n",
      "Epoch 61  --  loss 0.013\n",
      "Epoch 62  --  loss 0.013\n",
      "Epoch 63  --  loss 0.013\n",
      "Epoch 64  --  loss 0.013\n",
      "Epoch 65  --  loss 0.013\n",
      "Epoch 66  --  loss 0.013\n",
      "Epoch 67  --  loss 0.013\n",
      "Epoch 68  --  loss 0.013\n",
      "Epoch 69  --  loss 0.013\n",
      "Epoch 70  --  loss 0.013\n",
      "Epoch 71  --  loss 0.012\n",
      "Epoch 72  --  loss 0.012\n",
      "Epoch 73  --  loss 0.012\n",
      "Epoch 74  --  loss 0.012\n",
      "Epoch 75  --  loss 0.012\n",
      "Epoch 76  --  loss 0.012\n",
      "Epoch 77  --  loss 0.012\n",
      "Epoch 78  --  loss 0.012\n",
      "Epoch 79  --  loss 0.012\n",
      "Epoch 80  --  loss 0.012\n",
      "Epoch 81  --  loss 0.012\n",
      "Epoch 82  --  loss 0.012\n",
      "Epoch 83  --  loss 0.012\n",
      "Epoch 84  --  loss 0.012\n",
      "Epoch 85  --  loss 0.012\n",
      "Epoch 86  --  loss 0.012\n",
      "Epoch 87  --  loss 0.012\n",
      "Epoch 88  --  loss 0.012\n",
      "Epoch 89  --  loss 0.011\n",
      "Epoch 90  --  loss 0.011\n",
      "Epoch 91  --  loss 0.011\n",
      "Epoch 92  --  loss 0.011\n",
      "Epoch 93  --  loss 0.011\n",
      "Epoch 94  --  loss 0.011\n",
      "Epoch 95  --  loss 0.011\n",
      "Epoch 96  --  loss 0.011\n",
      "Epoch 97  --  loss 0.011\n",
      "Epoch 98  --  loss 0.011\n",
      "Epoch 99  --  loss 0.011\n",
      "Epoch 100  --  loss 0.011\n",
      "Epoch 101  --  loss 0.011\n",
      "Epoch 102  --  loss 0.011\n",
      "Epoch 103  --  loss 0.011\n",
      "Epoch 104  --  loss 0.011\n",
      "Epoch 105  --  loss 0.011\n",
      "Epoch 106  --  loss 0.011\n",
      "Epoch 107  --  loss 0.011\n",
      "Epoch 108  --  loss 0.011\n",
      "Epoch 109  --  loss 0.011\n",
      "Epoch 110  --  loss 0.011\n",
      "Epoch 111  --  loss 0.011\n",
      "Epoch 112  --  loss 0.011\n",
      "Epoch 113  --  loss 0.011\n",
      "Epoch 114  --  loss 0.011\n",
      "Epoch 115  --  loss 0.011\n",
      "Epoch 116  --  loss 0.011\n",
      "Epoch 117  --  loss 0.010\n",
      "Epoch 118  --  loss 0.010\n",
      "Epoch 119  --  loss 0.010\n",
      "Epoch 120  --  loss 0.010\n",
      "Epoch 121  --  loss 0.010\n",
      "Epoch 122  --  loss 0.010\n",
      "Epoch 123  --  loss 0.010\n",
      "Epoch 124  --  loss 0.010\n",
      "Epoch 125  --  loss 0.010\n",
      "Epoch 126  --  loss 0.010\n",
      "Epoch 127  --  loss 0.010\n",
      "Epoch 128  --  loss 0.010\n",
      "Epoch 129  --  loss 0.010\n",
      "Epoch 130  --  loss 0.010\n",
      "Epoch 131  --  loss 0.010\n",
      "Epoch 132  --  loss 0.010\n",
      "Epoch 133  --  loss 0.010\n",
      "Epoch 134  --  loss 0.010\n",
      "Epoch 135  --  loss 0.010\n",
      "Epoch 136  --  loss 0.010\n",
      "Epoch 137  --  loss 0.010\n",
      "Epoch 138  --  loss 0.010\n",
      "Epoch 139  --  loss 0.010\n",
      "Epoch 140  --  loss 0.010\n",
      "Epoch 141  --  loss 0.010\n",
      "Epoch 142  --  loss 0.010\n",
      "Epoch 143  --  loss 0.010\n",
      "Epoch 144  --  loss 0.010\n",
      "Epoch 145  --  loss 0.010\n",
      "Epoch 146  --  loss 0.010\n",
      "Epoch 147  --  loss 0.010\n",
      "Epoch 148  --  loss 0.010\n",
      "Epoch 149  --  loss 0.010\n",
      "Epoch 150  --  loss 0.010\n",
      "Epoch 151  --  loss 0.010\n",
      "Epoch 152  --  loss 0.010\n",
      "Epoch 153  --  loss 0.010\n",
      "Epoch 154  --  loss 0.010\n",
      "Epoch 155  --  loss 0.010\n",
      "Epoch 156  --  loss 0.010\n",
      "Epoch 157  --  loss 0.010\n",
      "Epoch 158  --  loss 0.010\n",
      "Epoch 159  --  loss 0.010\n",
      "Epoch 160  --  loss 0.010\n",
      "Epoch 161  --  loss 0.009\n",
      "Epoch 162  --  loss 0.009\n",
      "Epoch 163  --  loss 0.009\n",
      "Epoch 164  --  loss 0.009\n",
      "Epoch 165  --  loss 0.009\n",
      "Epoch 166  --  loss 0.009\n",
      "Epoch 167  --  loss 0.009\n",
      "Epoch 168  --  loss 0.009\n",
      "Epoch 169  --  loss 0.009\n",
      "Epoch 170  --  loss 0.009\n",
      "Epoch 171  --  loss 0.009\n",
      "Epoch 172  --  loss 0.009\n",
      "Epoch 173  --  loss 0.009\n",
      "Epoch 174  --  loss 0.009\n",
      "Epoch 175  --  loss 0.009\n",
      "Epoch 176  --  loss 0.009\n",
      "Epoch 177  --  loss 0.009\n",
      "Epoch 178  --  loss 0.009\n",
      "Epoch 179  --  loss 0.009\n",
      "Epoch 180  --  loss 0.009\n",
      "Epoch 181  --  loss 0.009\n",
      "Epoch 182  --  loss 0.009\n",
      "Epoch 183  --  loss 0.009\n",
      "Epoch 184  --  loss 0.009\n",
      "Epoch 185  --  loss 0.009\n",
      "Epoch 186  --  loss 0.009\n",
      "Epoch 187  --  loss 0.009\n",
      "Epoch 188  --  loss 0.009\n",
      "Epoch 189  --  loss 0.009\n",
      "Epoch 190  --  loss 0.009\n",
      "Epoch 191  --  loss 0.009\n",
      "Epoch 192  --  loss 0.009\n",
      "Epoch 193  --  loss 0.009\n",
      "Epoch 194  --  loss 0.009\n",
      "Epoch 195  --  loss 0.009\n",
      "Epoch 196  --  loss 0.009\n",
      "Epoch 197  --  loss 0.009\n",
      "Epoch 198  --  loss 0.009\n",
      "Epoch 199  --  loss 0.009\n",
      "Epoch 200  --  loss 0.009\n",
      "Epoch 201  --  loss 0.009\n",
      "Epoch 202  --  loss 0.009\n",
      "Epoch 203  --  loss 0.009\n",
      "Epoch 204  --  loss 0.009\n",
      "Epoch 205  --  loss 0.009\n",
      "Epoch 206  --  loss 0.009\n",
      "Epoch 207  --  loss 0.009\n",
      "Epoch 208  --  loss 0.009\n",
      "Epoch 209  --  loss 0.009\n",
      "Epoch 210  --  loss 0.009\n",
      "Epoch 211  --  loss 0.009\n",
      "Epoch 212  --  loss 0.009\n",
      "Epoch 213  --  loss 0.009\n",
      "Epoch 214  --  loss 0.009\n",
      "Epoch 215  --  loss 0.009\n",
      "Epoch 216  --  loss 0.009\n",
      "Epoch 217  --  loss 0.009\n",
      "Epoch 218  --  loss 0.009\n",
      "Epoch 219  --  loss 0.009\n",
      "Epoch 220  --  loss 0.009\n",
      "Epoch 221  --  loss 0.009\n",
      "Epoch 222  --  loss 0.009\n",
      "Epoch 223  --  loss 0.009\n",
      "Epoch 224  --  loss 0.009\n",
      "Epoch 225  --  loss 0.009\n",
      "Epoch 226  --  loss 0.009\n",
      "Epoch 227  --  loss 0.009\n",
      "Epoch 228  --  loss 0.009\n",
      "Epoch 229  --  loss 0.009\n",
      "Epoch 230  --  loss 0.009\n",
      "Epoch 231  --  loss 0.009\n",
      "Epoch 232  --  loss 0.009\n",
      "Epoch 233  --  loss 0.009\n",
      "Epoch 234  --  loss 0.009\n",
      "Epoch 235  --  loss 0.009\n",
      "Epoch 236  --  loss 0.009\n",
      "Epoch 237  --  loss 0.009\n",
      "Epoch 238  --  loss 0.009\n",
      "Epoch 239  --  loss 0.009\n",
      "Epoch 240  --  loss 0.009\n",
      "Epoch 241  --  loss 0.009\n",
      "Epoch 242  --  loss 0.009\n",
      "Epoch 243  --  loss 0.009\n",
      "Epoch 244  --  loss 0.009\n",
      "Epoch 245  --  loss 0.009\n",
      "Epoch 246  --  loss 0.009\n",
      "Epoch 247  --  loss 0.008\n",
      "Epoch 248  --  loss 0.008\n",
      "Epoch 249  --  loss 0.008\n",
      "Epoch 250  --  loss 0.008\n",
      "Epoch 251  --  loss 0.008\n",
      "Epoch 252  --  loss 0.008\n",
      "Epoch 253  --  loss 0.008\n",
      "Epoch 254  --  loss 0.008\n",
      "Epoch 255  --  loss 0.008\n",
      "Epoch 256  --  loss 0.008\n",
      "Epoch 257  --  loss 0.008\n",
      "Epoch 258  --  loss 0.008\n",
      "Epoch 259  --  loss 0.008\n",
      "Epoch 260  --  loss 0.008\n",
      "Epoch 261  --  loss 0.008\n",
      "Epoch 262  --  loss 0.008\n",
      "Epoch 263  --  loss 0.008\n",
      "Epoch 264  --  loss 0.008\n",
      "Epoch 265  --  loss 0.008\n",
      "Epoch 266  --  loss 0.008\n",
      "Epoch 267  --  loss 0.008\n",
      "Epoch 268  --  loss 0.008\n",
      "Epoch 269  --  loss 0.008\n",
      "Epoch 270  --  loss 0.008\n",
      "Epoch 271  --  loss 0.008\n",
      "Epoch 272  --  loss 0.008\n",
      "Epoch 273  --  loss 0.008\n",
      "Epoch 274  --  loss 0.008\n",
      "Epoch 275  --  loss 0.008\n",
      "Epoch 276  --  loss 0.008\n",
      "Epoch 277  --  loss 0.008\n",
      "Epoch 278  --  loss 0.008\n",
      "Epoch 279  --  loss 0.008\n",
      "Epoch 280  --  loss 0.008\n",
      "Epoch 281  --  loss 0.008\n",
      "Epoch 282  --  loss 0.008\n",
      "Epoch 283  --  loss 0.008\n",
      "Epoch 284  --  loss 0.008\n",
      "Epoch 285  --  loss 0.008\n",
      "Epoch 286  --  loss 0.008\n",
      "Epoch 287  --  loss 0.008\n",
      "Epoch 288  --  loss 0.008\n",
      "Epoch 289  --  loss 0.008\n",
      "Epoch 290  --  loss 0.008\n",
      "Epoch 291  --  loss 0.008\n",
      "Epoch 292  --  loss 0.008\n",
      "Epoch 293  --  loss 0.008\n",
      "Epoch 294  --  loss 0.008\n",
      "Epoch 295  --  loss 0.008\n",
      "Epoch 296  --  loss 0.008\n",
      "Epoch 297  --  loss 0.008\n",
      "Epoch 298  --  loss 0.008\n",
      "Epoch 299  --  loss 0.008\n",
      "Epoch 300  --  loss 0.008\n",
      "Epoch 301  --  loss 0.008\n",
      "Epoch 302  --  loss 0.008\n",
      "Epoch 303  --  loss 0.008\n",
      "Epoch 304  --  loss 0.008\n",
      "Epoch 305  --  loss 0.008\n",
      "Epoch 306  --  loss 0.008\n",
      "Epoch 307  --  loss 0.008\n",
      "Epoch 308  --  loss 0.008\n",
      "Epoch 309  --  loss 0.008\n",
      "Epoch 310  --  loss 0.008\n",
      "Epoch 311  --  loss 0.008\n",
      "Epoch 312  --  loss 0.008\n",
      "Epoch 313  --  loss 0.008\n",
      "Epoch 314  --  loss 0.008\n",
      "Epoch 315  --  loss 0.008\n",
      "Epoch 316  --  loss 0.008\n",
      "Epoch 317  --  loss 0.008\n",
      "Epoch 318  --  loss 0.008\n",
      "Epoch 319  --  loss 0.008\n",
      "Epoch 320  --  loss 0.008\n",
      "Epoch 321  --  loss 0.008\n",
      "Epoch 322  --  loss 0.008\n",
      "Epoch 323  --  loss 0.008\n",
      "Epoch 324  --  loss 0.008\n",
      "Epoch 325  --  loss 0.008\n",
      "Epoch 326  --  loss 0.008\n",
      "Epoch 327  --  loss 0.008\n",
      "Epoch 328  --  loss 0.008\n",
      "Epoch 329  --  loss 0.008\n",
      "Epoch 330  --  loss 0.008\n",
      "Epoch 331  --  loss 0.008\n",
      "Epoch 332  --  loss 0.008\n",
      "Epoch 333  --  loss 0.008\n",
      "Epoch 334  --  loss 0.008\n",
      "Epoch 335  --  loss 0.008\n",
      "Epoch 336  --  loss 0.008\n",
      "Epoch 337  --  loss 0.008\n",
      "Epoch 338  --  loss 0.008\n",
      "Epoch 339  --  loss 0.008\n",
      "Epoch 340  --  loss 0.008\n",
      "Epoch 341  --  loss 0.008\n",
      "Epoch 342  --  loss 0.008\n",
      "Epoch 343  --  loss 0.008\n",
      "Epoch 344  --  loss 0.008\n",
      "Epoch 345  --  loss 0.008\n",
      "Epoch 346  --  loss 0.008\n",
      "Epoch 347  --  loss 0.008\n",
      "Epoch 348  --  loss 0.008\n",
      "Epoch 349  --  loss 0.008\n",
      "Epoch 350  --  loss 0.008\n",
      "Epoch 351  --  loss 0.008\n",
      "Epoch 352  --  loss 0.008\n",
      "Epoch 353  --  loss 0.008\n",
      "Epoch 354  --  loss 0.008\n",
      "Epoch 355  --  loss 0.008\n",
      "Epoch 356  --  loss 0.008\n",
      "Epoch 357  --  loss 0.008\n",
      "Epoch 358  --  loss 0.008\n",
      "Epoch 359  --  loss 0.008\n",
      "Epoch 360  --  loss 0.008\n",
      "Epoch 361  --  loss 0.008\n",
      "Epoch 362  --  loss 0.008\n",
      "Epoch 363  --  loss 0.008\n",
      "Epoch 364  --  loss 0.008\n",
      "Epoch 365  --  loss 0.008\n",
      "Epoch 366  --  loss 0.008\n",
      "Epoch 367  --  loss 0.008\n",
      "Epoch 368  --  loss 0.008\n",
      "Epoch 369  --  loss 0.008\n",
      "Epoch 370  --  loss 0.008\n",
      "Epoch 371  --  loss 0.008\n",
      "Epoch 372  --  loss 0.008\n",
      "Epoch 373  --  loss 0.008\n",
      "Epoch 374  --  loss 0.008\n",
      "Epoch 375  --  loss 0.008\n",
      "Epoch 376  --  loss 0.008\n",
      "Epoch 377  --  loss 0.008\n",
      "Epoch 378  --  loss 0.008\n",
      "Epoch 379  --  loss 0.008\n",
      "Epoch 380  --  loss 0.008\n",
      "Epoch 381  --  loss 0.008\n",
      "Epoch 382  --  loss 0.008\n",
      "Epoch 383  --  loss 0.008\n",
      "Epoch 384  --  loss 0.008\n",
      "Epoch 385  --  loss 0.008\n",
      "Epoch 386  --  loss 0.008\n",
      "Epoch 387  --  loss 0.008\n",
      "Epoch 388  --  loss 0.008\n",
      "Epoch 389  --  loss 0.008\n",
      "Epoch 390  --  loss 0.008\n",
      "Epoch 391  --  loss 0.008\n",
      "Epoch 392  --  loss 0.008\n",
      "Epoch 393  --  loss 0.008\n",
      "Epoch 394  --  loss 0.008\n",
      "Epoch 395  --  loss 0.008\n",
      "Epoch 396  --  loss 0.008\n",
      "Epoch 397  --  loss 0.008\n",
      "Epoch 398  --  loss 0.008\n",
      "Epoch 399  --  loss 0.008\n",
      "Epoch 400  --  loss 0.008\n",
      "Epoch 401  --  loss 0.008\n",
      "Epoch 402  --  loss 0.008\n",
      "Epoch 403  --  loss 0.008\n",
      "Epoch 404  --  loss 0.008\n",
      "Epoch 405  --  loss 0.008\n",
      "Epoch 406  --  loss 0.008\n",
      "Epoch 407  --  loss 0.008\n",
      "Epoch 408  --  loss 0.008\n",
      "Epoch 409  --  loss 0.008\n",
      "Epoch 410  --  loss 0.008\n",
      "Epoch 411  --  loss 0.008\n",
      "Epoch 412  --  loss 0.008\n",
      "Epoch 413  --  loss 0.008\n",
      "Epoch 414  --  loss 0.008\n",
      "Epoch 415  --  loss 0.008\n",
      "Epoch 416  --  loss 0.008\n",
      "Epoch 417  --  loss 0.008\n",
      "Epoch 418  --  loss 0.008\n",
      "Epoch 419  --  loss 0.008\n",
      "Epoch 420  --  loss 0.008\n",
      "Epoch 421  --  loss 0.008\n",
      "Epoch 422  --  loss 0.008\n",
      "Epoch 423  --  loss 0.008\n",
      "Epoch 424  --  loss 0.008\n",
      "Epoch 425  --  loss 0.008\n",
      "Epoch 426  --  loss 0.008\n",
      "Epoch 427  --  loss 0.008\n",
      "Epoch 428  --  loss 0.008\n",
      "Epoch 429  --  loss 0.008\n",
      "Epoch 430  --  loss 0.008\n",
      "Epoch 431  --  loss 0.008\n",
      "Epoch 432  --  loss 0.008\n",
      "Epoch 433  --  loss 0.008\n",
      "Epoch 434  --  loss 0.008\n",
      "Epoch 435  --  loss 0.008\n",
      "Epoch 436  --  loss 0.008\n",
      "Epoch 437  --  loss 0.008\n",
      "Epoch 438  --  loss 0.008\n",
      "Epoch 439  --  loss 0.008\n",
      "Epoch 440  --  loss 0.008\n",
      "Epoch 441  --  loss 0.008\n",
      "Epoch 442  --  loss 0.008\n",
      "Epoch 443  --  loss 0.008\n",
      "Epoch 444  --  loss 0.008\n",
      "Epoch 445  --  loss 0.008\n",
      "Epoch 446  --  loss 0.008\n",
      "Epoch 447  --  loss 0.008\n",
      "Epoch 448  --  loss 0.008\n",
      "Epoch 449  --  loss 0.008\n",
      "Epoch 450  --  loss 0.008\n",
      "Epoch 451  --  loss 0.008\n",
      "Epoch 452  --  loss 0.008\n",
      "Epoch 453  --  loss 0.008\n",
      "Epoch 454  --  loss 0.008\n",
      "Epoch 455  --  loss 0.008\n",
      "Epoch 456  --  loss 0.008\n",
      "Epoch 457  --  loss 0.008\n",
      "Epoch 458  --  loss 0.008\n",
      "Epoch 459  --  loss 0.008\n",
      "Epoch 460  --  loss 0.008\n",
      "Epoch 461  --  loss 0.008\n",
      "Epoch 462  --  loss 0.008\n",
      "Epoch 463  --  loss 0.008\n",
      "Epoch 464  --  loss 0.008\n",
      "Epoch 465  --  loss 0.008\n",
      "Epoch 466  --  loss 0.008\n",
      "Epoch 467  --  loss 0.008\n",
      "Epoch 468  --  loss 0.008\n",
      "Epoch 469  --  loss 0.008\n",
      "Epoch 470  --  loss 0.008\n",
      "Epoch 471  --  loss 0.008\n",
      "Epoch 472  --  loss 0.008\n",
      "Epoch 473  --  loss 0.008\n",
      "Epoch 474  --  loss 0.008\n",
      "Epoch 475  --  loss 0.008\n",
      "Epoch 476  --  loss 0.008\n",
      "Epoch 477  --  loss 0.008\n",
      "Epoch 478  --  loss 0.008\n",
      "Epoch 479  --  loss 0.008\n",
      "Epoch 480  --  loss 0.008\n",
      "Epoch 481  --  loss 0.008\n",
      "Epoch 482  --  loss 0.008\n",
      "Epoch 483  --  loss 0.008\n",
      "Epoch 484  --  loss 0.008\n",
      "Epoch 485  --  loss 0.008\n",
      "Epoch 486  --  loss 0.008\n",
      "Epoch 487  --  loss 0.008\n",
      "Epoch 488  --  loss 0.008\n",
      "Epoch 489  --  loss 0.008\n",
      "Epoch 490  --  loss 0.008\n",
      "Epoch 491  --  loss 0.008\n",
      "Epoch 492  --  loss 0.008\n",
      "Epoch 493  --  loss 0.008\n",
      "Epoch 494  --  loss 0.008\n",
      "Epoch 495  --  loss 0.008\n",
      "Epoch 496  --  loss 0.008\n",
      "Epoch 497  --  loss 0.008\n",
      "Epoch 498  --  loss 0.007\n",
      "Epoch 499  --  loss 0.008\n"
     ]
    }
   ],
   "source": [
    "from models.metrics import MeanSquaredError\n",
    "\n",
    "autoencoder = Autoencoder(input_dim=flatten_dim, code_dim=108, encoder_hidden_count=1, reduce_by=1.5)\n",
    "optimizer = Optimizer(\n",
    "    autoencoder,\n",
    "    loss=MeanSquaredError(),\n",
    "    learning_rate=0.9,\n",
    "    batch_size=128,\n",
    "    epochs=500,\n",
    ")\n",
    "    \n",
    "optimizer.fit(X_train, X_train)\n",
    "\n",
    "pickle_results(optimizer, autoencoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (main, Jan 15 2022, 18:02:07) [GCC 9.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
